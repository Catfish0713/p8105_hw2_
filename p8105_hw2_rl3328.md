p8105_hw2_rl3328
================
Ruixi Li
2023-09-28

# import and clean data

``` r
library(tidyverse)
library(readr)
library(readxl)
```

# Problem 1

## import and clean pols-month

``` r
pols = 
  read_csv("./data/fivethirtyeight_datasets/fivethirtyeight_datasets/pols-month.csv") |>
  janitor::clean_names() |>#this step can be ignored cuz the variable names are clean
  separate(
    col = mon, 
    into = c("year","month","day"), 
    sep = "-") |>#I used `remove = FALSE` to check if I have done it correctly(not shown)
  mutate(month = tolower(month.abb[as.numeric(month)]))|>#I assume month name is abbreviation
  mutate(president =recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  select(-c("prez_gop","prez_dem","day"))
```

## import and clean snp

After knowing the range of years, I assign the date into correct
century.

``` r
snp = 
  read_csv("./data/fivethirtyeight_datasets/fivethirtyeight_datasets/snp.csv") |>
  janitor::clean_names() |>#this step can be ignored cuz the variable names are clean
  separate(
    col = date, 
    into = c("month","day","year"), 
    sep = "/") |>#I used `remove = FALSE` to check if I have done it correctly(not shown)
  mutate(year = ifelse(as.numeric(year)>15, 1900+as.numeric(year), 2000+as.numeric(year)),
         month = tolower(month.abb[as.numeric(month)])) |>
  select(-"day")
```

## import and clean unemployment

``` r
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/fivethirtyeight_datasets/unemployment.csv") |>
  janitor::clean_names() |>
  pivot_longer(
    -year,
    names_to = "month", 
    values_to = "unemployment")  
```

## merge three datasets together

Join the datasets by merging `snp`into `pols`, and merging
`unemployment` into the result.

``` r
snp = snp |> mutate(year = as.character(year))

results = left_join(pols, snp, by = c("year","month"))

unemployment = unemployment |> mutate(year = as.character(year))

results = left_join(results, unemployment, by = c("year","month"))
```

# Problem 2

## import and clean mr. transh wheel

``` r
mr = read_excel("./data/trash.xlsx", 1) |>
  janitor::clean_names() |>
  select(-c(15,16)) |>
  mutate(month = ifelse(month == "Decemeber","December",month),
         sports_balls = round(sports_balls))

str(mr)
```

    ## tibble [548 × 14] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:548] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:548] "May" "May" "May" "May" ...
    ##  $ year              : chr [1:548] "2014" "2014" "2014" "2014" ...
    ##  $ date              : POSIXct[1:548], format: "2014-05-16" "2014-05-16" ...
    ##  $ weight_tons       : num [1:548] 4.31 2.74 3.45 3.1 4.06 2.71 1.91 3.7 2.52 3.76 ...
    ##  $ volume_cubic_yards: num [1:548] 18 13 15 15 18 13 8 16 14 18 ...
    ##  $ plastic_bottles   : num [1:548] 1450 1120 2450 2380 980 1430 910 3580 2400 1340 ...
    ##  $ polystyrene       : num [1:548] 1820 1030 3100 2730 870 2140 1090 4310 2790 1730 ...
    ##  $ cigarette_butts   : num [1:548] 126000 91000 105000 100000 120000 90000 56000 112000 98000 130000 ...
    ##  $ glass_bottles     : num [1:548] 72 42 50 52 72 46 32 58 49 75 ...
    ##  $ grocery_bags      : num [1:548] 584 496 1080 896 368 ...
    ##  $ chip_bags         : num [1:548] 1162 874 2032 1971 753 ...
    ##  $ sports_balls      : num [1:548] 7 5 6 6 7 5 3 6 6 7 ...
    ##  $ homes_powered     : num [1:548] 0 0 0 0 0 0 0 0 0 0 ...

``` r
summary(mr)
```

    ##     dumpster        month               year          
    ##  Min.   :  1.0   Length:548         Length:548        
    ##  1st Qu.:137.5   Class :character   Class :character  
    ##  Median :274.0   Mode  :character   Mode  :character  
    ##  Mean   :274.0                                        
    ##  3rd Qu.:410.5                                        
    ##  Max.   :547.0                                        
    ##  NA's   :1                                            
    ##       date                         weight_tons       volume_cubic_yards
    ##  Min.   :1900-01-20 00:00:00.00   Min.   :   0.780   Min.   :   7.0    
    ##  1st Qu.:2016-06-15 12:00:00.00   1st Qu.:   2.710   1st Qu.:  15.0    
    ##  Median :2018-07-18 00:00:00.00   Median :   3.190   Median :  15.0    
    ##  Mean   :2018-04-03 12:38:10.30   Mean   :   6.381   Mean   :  30.6    
    ##  3rd Qu.:2020-06-24 00:00:00.00   3rd Qu.:   3.730   3rd Qu.:  15.0    
    ##  Max.   :2022-07-29 00:00:00.00   Max.   :1748.360   Max.   :8385.0    
    ##  NA's   :1                                                             
    ##  plastic_bottles    polystyrene       cigarette_butts    glass_bottles     
    ##  Min.   :    210   Min.   :    48.0   Min.   :     900   Min.   :    0.00  
    ##  1st Qu.:    980   1st Qu.:   702.5   1st Qu.:    4000   1st Qu.:   10.00  
    ##  Median :   1880   Median :  1265.0   Median :    7000   Median :   18.00  
    ##  Mean   :   3910   Mean   :  3292.1   Mean   :   41774   Mean   :   43.23  
    ##  3rd Qu.:   2745   3rd Qu.:  2500.0   3rd Qu.:   27000   3rd Qu.:   31.00  
    ##  Max.   :1071295   Max.   :902045.0   Max.   :11446020   Max.   :11844.00  
    ##                                                                            
    ##   grocery_bags      chip_bags       sports_balls    homes_powered     
    ##  Min.   :    24   Min.   :   180   Min.   :   0.0   Min.   :    0.00  
    ##  1st Qu.:   330   1st Qu.:   740   1st Qu.:   6.0   1st Qu.:   39.58  
    ##  Median :   684   Median :  1100   Median :  11.0   Median :   51.17  
    ##  Mean   :  1928   Mean   :  2832   Mean   :  25.1   Mean   :   91.76  
    ##  3rd Qu.:  1378   3rd Qu.:  1982   3rd Qu.:  18.0   3rd Qu.:   59.33  
    ##  Max.   :528146   Max.   :775969   Max.   :6879.0   Max.   :22344.00  
    ##                                                     NA's   :61

- there’s one `NA` in `dumpster` variable, one `NA` in `date` variable
  and 61 `NAs` in `homes_powered` variable.

- I don’t like the input file name with space, so I changed the name of
  it.

- delete this row whose dumpster is `NA`

``` r
mr = drop_na(mr, dumpster)
```

- calculate homes powered

- according to `home powered note`, Homes Powered - Each ton of trash
  equates to on average 500 kilowatts of electricity. An average
  household will use 30 kilowatts per day.

``` r
mr = mr |> mutate(homes_powered = (weight_tons*500)/30,
                  trash_wheel_name = "Mr.Trash Wheel")
```

I can integrate the seperated codes into one using pipeline, but I am
showing my process of thinking.

## import and clean Professor Trash Wheel and Gwynnda

``` r
pro = read_excel("./data/trash.xlsx", 2) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(homes_powered = (weight_tons*500)/30,
         trash_wheel_name = "Professor Trash Wheel",
         year = as.character(year))
  

str(pro)
```

    ## tibble [94 × 14] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:94] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:94] "January" "January" "February" "February" ...
    ##  $ year              : chr [1:94] "2017" "2017" "2017" "2017" ...
    ##  $ date              : POSIXct[1:94], format: "2017-01-02" "2017-01-30" ...
    ##  $ weight_tons       : num [1:94] 1.79 1.58 2.32 3.72 1.45 1.71 1.82 2.37 2.64 2.78 ...
    ##  $ volume_cubic_yards: num [1:94] 15 15 18 15 15 15 15 15 15 15 ...
    ##  $ plastic_bottles   : num [1:94] 1950 9540 8350 8590 7830 8210 9830 9240 9540 8230 ...
    ##  $ polystyrene       : num [1:94] 6080 11230 9210 1030 9950 ...
    ##  $ cigarette_butts   : num [1:94] 19700 17600 12000 13000 16000 14000 17000 15000 17000 13000 ...
    ##  $ glass_bottles     : num [1:94] 8 14 19 21 18 23 26 14 28 22 ...
    ##  $ grocery_bags      : num [1:94] 3100 5630 6430 5870 7450 ...
    ##  $ chip_bags         : num [1:94] 15600 16700 12400 11030 15340 ...
    ##  $ homes_powered     : num [1:94] 29.8 26.3 38.7 62 24.2 ...
    ##  $ trash_wheel_name  : chr [1:94] "Professor Trash Wheel" "Professor Trash Wheel" "Professor Trash Wheel" "Professor Trash Wheel" ...

``` r
summary(pro)
```

    ##     dumpster        month               year          
    ##  Min.   : 1.00   Length:94          Length:94         
    ##  1st Qu.:24.25   Class :character   Class :character  
    ##  Median :47.50   Mode  :character   Mode  :character  
    ##  Mean   :47.50                                        
    ##  3rd Qu.:70.75                                        
    ##  Max.   :94.00                                        
    ##       date                         weight_tons    volume_cubic_yards
    ##  Min.   :2017-01-02 00:00:00.00   Min.   :0.610   Min.   : 6.00     
    ##  1st Qu.:2018-04-17 00:00:00.00   1st Qu.:1.580   1st Qu.:15.00     
    ##  Median :2019-04-24 00:00:00.00   Median :1.935   Median :15.00     
    ##  Mean   :2019-07-22 06:38:17.86   Mean   :2.023   Mean   :14.59     
    ##  3rd Qu.:2020-12-26 12:00:00.00   3rd Qu.:2.487   3rd Qu.:15.00     
    ##  Max.   :2022-07-18 00:00:00.00   Max.   :3.720   Max.   :18.00     
    ##  plastic_bottles  polystyrene    cigarette_butts glass_bottles 
    ##  Min.   : 657    Min.   :  280   Min.   : 4200   Min.   : 0.0  
    ##  1st Qu.:3925    1st Qu.: 1535   1st Qu.: 7250   1st Qu.: 6.5  
    ##  Median :5050    Median : 4000   Median : 9700   Median :14.0  
    ##  Mean   :5411    Mean   : 4648   Mean   :12324   Mean   :15.2  
    ##  3rd Qu.:7400    3rd Qu.: 7800   3rd Qu.:16000   3rd Qu.:22.0  
    ##  Max.   :9830    Max.   :11528   Max.   :33320   Max.   :48.0  
    ##   grocery_bags       chip_bags     homes_powered   trash_wheel_name  
    ##  Min.   :  270.0   Min.   : 2900   Min.   :10.17   Length:94         
    ##  1st Qu.:  882.5   1st Qu.: 4900   1st Qu.:26.33   Class :character  
    ##  Median : 1200.0   Median : 6400   Median :32.25   Mode  :character  
    ##  Mean   : 2684.8   Mean   : 8149   Mean   :33.71                     
    ##  3rd Qu.: 2050.0   3rd Qu.:10400   3rd Qu.:41.46                     
    ##  Max.   :13450.0   Max.   :20100   Max.   :62.00

``` r
gwy = read_excel("./data/trash.xlsx", 4) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(homes_powered = (weight_tons*500)/30,
         trash_wheel_name = "Gwynnda Trash Wheel",
         year = as.character(year),
         month = ifelse(month == "july","July",month))


str(gwy)
```

    ## tibble [106 × 12] (S3: tbl_df/tbl/data.frame)
    ##  $ dumpster          : num [1:106] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ month             : chr [1:106] "July" "July" "July" "July" ...
    ##  $ year              : chr [1:106] "2021" "2021" "2021" "2021" ...
    ##  $ date              : POSIXct[1:106], format: "2021-07-03" "2021-07-07" ...
    ##  $ weight_tons       : num [1:106] 0.93 2.26 1.62 1.76 1.53 2.06 1.9 2.16 2.6 3.21 ...
    ##  $ volume_cubic_yards: num [1:106] 15 15 15 15 15 15 15 15 15 15 ...
    ##  $ plastic_bottles   : num [1:106] 1200 2000 1800 1000 2100 2400 2700 3000 980 240 ...
    ##  $ polystyrene       : num [1:106] 360 240 270 180 240 360 320 320 180 42 ...
    ##  $ cigarette_butts   : num [1:106] 3400 3900 2900 2100 4000 3900 4200 4000 1800 400 ...
    ##  $ plastic_bags      : num [1:106] 1800 2200 2400 1800 2700 3000 3200 3600 1000 360 ...
    ##  $ homes_powered     : num [1:106] 15.5 37.7 27 29.3 25.5 ...
    ##  $ trash_wheel_name  : chr [1:106] "Gwynnda Trash Wheel" "Gwynnda Trash Wheel" "Gwynnda Trash Wheel" "Gwynnda Trash Wheel" ...

``` r
summary(gwy)
```

    ##     dumpster         month               year          
    ##  Min.   :  1.00   Length:106         Length:106        
    ##  1st Qu.: 26.25   Class :character   Class :character  
    ##  Median : 52.50   Mode  :character   Mode  :character  
    ##  Mean   : 52.70                                        
    ##  3rd Qu.: 78.75                                        
    ##  Max.   :105.00                                        
    ##       date                         weight_tons    volume_cubic_yards
    ##  Min.   :2021-07-03 00:00:00.00   Min.   :0.770   Min.   : 5.00     
    ##  1st Qu.:2021-10-29 06:00:00.00   1st Qu.:2.542   1st Qu.:15.00     
    ##  Median :2022-01-17 12:00:00.00   Median :3.070   Median :15.00     
    ##  Mean   :2022-01-29 19:14:43.01   Mean   :2.932   Mean   :14.86     
    ##  3rd Qu.:2022-06-11 00:00:00.00   3rd Qu.:3.400   3rd Qu.:15.00     
    ##  Max.   :2022-07-26 00:00:00.00   Max.   :4.180   Max.   :15.00     
    ##  plastic_bottles  polystyrene    cigarette_butts  plastic_bags   
    ##  Min.   :   0    Min.   :  0.0   Min.   :   0    Min.   :   0.0  
    ##  1st Qu.: 480    1st Qu.: 60.0   1st Qu.: 980    1st Qu.: 242.5  
    ##  Median :1000    Median :155.0   Median :2000    Median : 810.0  
    ##  Mean   :1239    Mean   :164.1   Mean   :2188    Mean   : 977.6  
    ##  3rd Qu.:1950    3rd Qu.:240.0   3rd Qu.:3350    3rd Qu.:1475.0  
    ##  Max.   :4200    Max.   :500.0   Max.   :6400    Max.   :3600.0  
    ##  homes_powered   trash_wheel_name  
    ##  Min.   :12.83   Length:106        
    ##  1st Qu.:42.38   Class :character  
    ##  Median :51.17   Mode  :character  
    ##  Mean   :48.86                     
    ##  3rd Qu.:56.67                     
    ##  Max.   :69.67

## combine them together

``` r
trash =  bind_rows(mr,gwy,pro)
```

Let’s talk about the Mr. Trash Wheel datasets. The `mr` data has 547
observations and 15 variables and tells us about the amount of trash the
dumpster receives(measured by both weight `weight_tons` and volume
`volume_cubic_yards`), fill time`month`,`year`,`date` and the categories
of trashplastic_bottles, polystyrene, cigarette_butts, glass_bottles,
grocery_bags, chip_bags, sports_balls, homes_powered, trash_wheel_name
for “Mr. Trash Wheel” from years 2014 to 2022. It also tells us how many
homes can be powered by the electricity produced by trash incineration.
The `pro` data has 94 observations and 14 variables, ranging from years
2017 to 2022. The `gwy` data has 106 observations and 12 variables
ranging from years 2021 to 2022.**The total weight of trash collected by
Professor Trash Wheel was 190.12**. **The total number of cigarette
butts collected by Gwynnda in July of 2021 was 1.63^{4}**.

# Problem 3

## import and clean baseline

``` r
baseline = read_csv("./data/data_mci/MCI_baseline.csv",col_names = FALSE) |>
  slice(-c(1,2)) |>
  magrittr::set_colnames(c("ID","current_age","sex","education","apoe4","age_at_onset")) |>
  janitor::clean_names() |>
  mutate(
    apoe4 = recode(apoe4, "1" = "APOE4 carrier","0" = "APOE4 non-carrier"),
    sex = recode(sex, "1" = "Male", "0" = "Female"),
    current_age = as.numeric(current_age),
    age_at_onset = ifelse(age_at_onset == ".", NA, age_at_onset),
    age_at_onset = as.numeric(age_at_onset)) |>
  filter(current_age<age_at_onset | is.na(age_at_onset))

str(baseline)
```

    ## tibble [479 × 6] (S3: tbl_df/tbl/data.frame)
    ##  $ id          : chr [1:479] "1" "2" "3" "4" ...
    ##  $ current_age : num [1:479] 63.1 65.6 62.5 69.8 66 62.5 66.5 67.2 66.7 64.1 ...
    ##  $ sex         : chr [1:479] "Female" "Female" "Male" "Female" ...
    ##  $ education   : chr [1:479] "16" "20" "16" "16" ...
    ##  $ apoe4       : chr [1:479] "APOE4 carrier" "APOE4 carrier" "APOE4 carrier" "APOE4 non-carrier" ...
    ##  $ age_at_onset: num [1:479] NA NA 66.8 NA 68.7 NA 74 NA NA NA ...

``` r
summary(baseline)
```

    ##       id             current_age        sex             education        
    ##  Length:479         Min.   :56.00   Length:479         Length:479        
    ##  Class :character   1st Qu.:63.15   Class :character   Class :character  
    ##  Mode  :character   Median :64.90   Mode  :character   Mode  :character  
    ##                     Mean   :65.03                                        
    ##                     3rd Qu.:67.00                                        
    ##                     Max.   :72.90                                        
    ##                                                                          
    ##     apoe4            age_at_onset  
    ##  Length:479         Min.   :61.20  
    ##  Class :character   1st Qu.:68.20  
    ##  Mode  :character   Median :70.20  
    ##                     Mean   :70.41  
    ##                     3rd Qu.:73.40  
    ##                     Max.   :77.20  
    ##                     NA's   :386

``` r
prop.table(table(baseline$apoe4))
```

    ## 
    ##     APOE4 carrier APOE4 non-carrier 
    ##         0.3006263         0.6993737

- When importing `baseline` data, I first drop the first row of the
  dataset(after memorizing the decoding rules) and then used the second
  row as column names. After cleaning the column names, I recoded `sex`
  and `apoe4`. Since `current_age` and `age_at_onset` are all character
  type in the original file. I converted them as numeric before
  comparing them to identify not MCI-free subjects at baseline and
  replace “.” with `na`in age_at_onset. No duplicate `id` in `baseline`
  data.
- The `baseline` data has 479 observations and 6 variables and tells us
  about the demographic features at baseline(sex, current_age,apoe4
  status, education and MCI status during follow-up).
- 479 participants were recruited, and of these 93 develop MCI. The
  average baseline age is 65.0286013. 30.1% of women in the study are
  APOE4 carriers.

## import and clean amyloid data

``` r
amyloid = read_csv("./data/data_mci/mci_amyloid.csv",col_names = FALSE) |>
  slice(-c(1,2)) |>
  magrittr::set_colnames(c("ID","abeta_40/42_bsl","abeta_40/42_2","abeta_40/42_4","abeta_40/42_6","abeta_40/42_8")) |>
  janitor::clean_names() |>
  mutate_at(c(2:6), as.numeric)
```

    ## Warning: There were 5 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `abeta_40_42_bsl = .Primitive("as.double")(abeta_40_42_bsl)`.
    ## Caused by warning:
    ## ! NAs introduced by coercion
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 4 remaining warnings.

``` r
str(amyloid)
```

    ## tibble [487 × 6] (S3: tbl_df/tbl/data.frame)
    ##  $ id             : chr [1:487] "1" "2" "3" "4" ...
    ##  $ abeta_40_42_bsl: num [1:487] 0.111 0.107 0.106 0.109 0.108 ...
    ##  $ abeta_40_42_2  : num [1:487] NA 0.109 0.109 0.109 0.112 ...
    ##  $ abeta_40_42_4  : num [1:487] 0.109 0.109 0.106 0.111 0.115 ...
    ##  $ abeta_40_42_6  : num [1:487] 0.105 0.106 NA 0.107 0.107 ...
    ##  $ abeta_40_42_8  : num [1:487] 0.107 0.107 0.106 0.111 0.106 ...

``` r
summary(amyloid)
```

    ##       id            abeta_40_42_bsl  abeta_40_42_2    abeta_40_42_4  
    ##  Length:487         Min.   :0.1015   Min.   :0.1025   Min.   :0.101  
    ##  Class :character   1st Qu.:0.1090   1st Qu.:0.1083   1st Qu.:0.108  
    ##  Mode  :character   Median :0.1111   Median :0.1105   Median :0.110  
    ##                     Mean   :0.1110   Mean   :0.1103   Mean   :0.110  
    ##                     3rd Qu.:0.1131   3rd Qu.:0.1122   3rd Qu.:0.112  
    ##                     Max.   :0.1184   Max.   :0.1187   Max.   :0.118  
    ##                     NA's   :2        NA's   :50       NA's   :43     
    ##  abeta_40_42_6    abeta_40_42_8    
    ##  Min.   :0.1005   Min.   :0.09938  
    ##  1st Qu.:0.1069   1st Qu.:0.10615  
    ##  Median :0.1089   Median :0.10842  
    ##  Mean   :0.1089   Mean   :0.10824  
    ##  3rd Qu.:0.1112   3rd Qu.:0.11045  
    ##  Max.   :0.1180   Max.   :0.11586  
    ##  NA's   :39       NA's   :38

- When importing `baseline` data, I first drop the first row of the
  dataset(after memorizing the decoding rules) and then used the second
  row(modified a little) as column names. I found there’s “Na” in
  follow-up columns, so I converted them into numeric so that some
  strings unable to be converted directly became `NA` . No duplicate
  `id` in the `amyloid` data.

## check and combine

``` r
a <- left_join(baseline,amyloid,by="id")
b <- right_join(baseline,amyloid,by="id")
merge <- inner_join(baseline,amyloid,by="id")
d <- full_join(baseline,amyloid,by="id")
```

- there’s 471 participants have both `baseline` and `amyloid` data; 8
  participants only appear in `baseline` data; 16 participants only
  appear in `amyloid` data.
- `merge` dataset has 471 observations and 11 variables and gave us 471
  participants’ demographic features and their Amyloid 40/42 ratio
  during follow-up time point.

``` r
write_csv(merge,"merge.csv")
```
